# Introduction to Regelum: Python Framework for Reinforcement Learning and Optimal Control

Welcome to the tutorial on Regelum, a Python framework for reinforcement learning and optimal control. In this tutorial, we will cover all the key concepts and functionality of the framework, providing you with a step-by-step guide to understanding and utilizing Regelum effectively.

## Who is this tutorial for?

This tutorial is designed for engineers, researchers, and enthusiasts who are interested in reinforcement learning and optimal control techniques. Whether you are a seasoned professional or just starting your journey in this field, this tutorial will provide you with the knowledge and practical skills needed to leverage Regelum for solving complex control problems.

## What is Regelum?

Regelum is a versatile framework that combines the principles of reinforcement learning and optimal control to enable you to design and implement sophisticated control strategies. It provides a flexible interface for developing and deploying control algorithms, making it easier for you to experiment, iterate, and optimize your control systems.

## Tutorial Structure

TODO revision of the sections

To ensure a smooth learning experience, this tutorial follows a linear structure, gradually introducing you to the key ideas and concepts of the Regelum framework. Here is an overview of the tutorial sections:

1. Introduction: This section (you're currently reading) provides an overview of Regelum and sets the stage for the rest of the tutorial.

2. Basic Concepts: In this section, we will explore the fundamental concepts underlying reinforcement learning and optimal control. This includes an introduction to state, action, reward, and the dynamics of a system.

3. Implementing your own dynamical system: Here, we will dive into the practical aspects of implementing a dynamical system within the Regelum framework. You will learn how to define the state and action spaces, as well as the dynamics of your system.

4. Run your system in a simulator: This section focuses on using simulators to evaluate the performance of your control system. We will guide you through the process of integrating your system with a simulator and running simulations.

5. Policy: The policy is a crucial component in reinforcement learning. In this section, you will learn how to define and train policies using Regelum, enabling your control system to make intelligent decisions.

6. Model Predictive Control (MPC): MPC is a powerful technique for optimizing control actions in real-time. Here, we will explore how to implement MPC using Regelum, enabling your system to adapt and respond to changing environments.

7. REINFORCE: REINFORCE is a policy optimization method that uses the Monte Carlo approach. In this section, we will delve into the details of implementing REINFORCE in Regelum, allowing your system to learn from interactions and improve its performance.

8. Critic for ACPG: Advantage-Actor Critic with Generalized Policy Gradient (ACPG) combines value estimation with policy optimization. In this section, we will explore how to incorporate a critic into your control system using Regelum, enhancing its decision-making capabilities.

9. Configuring your experiment: In this section, we will guide you on how to configure and customize your control experiments in Regelum. You will learn how to fine-tune various parameters to achieve optimal performance.

10. MLflow: MLflow is a powerful tool for managing and tracking experiments. Here, we will show you how to integrate MLflow with Regelum, enabling you to easily log and monitor your control experiments.

11. Best Practices: In the final section, we will share some best practices and tips for effectively using Regelum. This includes guidelines for system design, training strategies, and performance evaluation.

By the end of this tutorial, you will have a solid understanding of the Regelum framework and be equipped with the skills to apply reinforcement learning and optimal control techniques to solve real-world control problems.

Happy learning, and may your code run error-free!