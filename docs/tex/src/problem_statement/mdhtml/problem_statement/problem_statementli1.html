<!DOCTYPE html>

<html lang="en-US" xml:lang="en-US">
<head><title>Problem statement</title>
<meta charset="utf-8"/>
<meta content="TeX4ht (https://tug.org/tex4ht/)" name="generator"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="problem_statement.tex" name="src"/>
<script>window.MathJax = { tex: { tags: "ams", }, }; </script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<meta id="problem-statement" link="x2-1000" md-heading="Problem statement" name="md-heading" type="h3"/></head><body>
<!-- l. 8 -->
<!-- l. 10 --><p class="noindent">Reinforcement learning deals with a special kind of Markov Decision Problems (MDPs)
which have a normed vector space as a state-space: \begin {equation}  \left (\states , \actions , \transit , \Cost \right ),  \end {equation}<a id="x2-1001r1"></a> where:
      </p><dl class="enumerate-enumitem"><dt class="enumerate-enumitem">
   1. </dt><dd class="enumerate-enumitem">\(\states \) is the <span class="cmti-12">state space</span>, that is a normed vector space of all states of the given
      environment;
      </dd><dt class="enumerate-enumitem">
   2. </dt><dd class="enumerate-enumitem">\(\actions \) is the <span class="cmti-12">action space</span>, that is a set of all actions available to the agent;
      </dd><dt class="enumerate-enumitem">
   3. </dt><dd class="enumerate-enumitem">\(\transit : \states \times \actions \times \states \ \rightarrow \ \R \) is the <span class="cmti-12">transition probability density function </span>of the environment, that is such
      function that \(\transit (\cdot \mid \state _{t}, \action _{t})\) is the probability density of the next state \(s_{t + 1}\) conditioned on the
      current state \(\state _{t}\) and current action \(\action _{t}\);
      </dd><dt class="enumerate-enumitem">
   4. </dt><dd class="enumerate-enumitem">\(\Cost : \states \times \actions \rightarrow \mathbb {R}\) is the <span class="cmti-12">cost function </span>of the environment, that is a function that takes a state \(\state _{t}\)
      and an action \(\action _{t}\) and returns the immediate cost \(\cost _{t}\) incurred upon the agent if it
      were to perform action \(\action _{t}\) while in state \(\state _{t}\);</dd></dl>
<!-- l. 24 --><p class="noindent"><span class="cmbx-12">The goal of reinforcement learning </span>is to find a policy \(\policy \) that minimizes \(V^{\policy }(\state _0) = \E {\sum _{t = 0}^{\infty }\gamma ^{t}\Cost (\state _{t}, \action _{t})}\) for some
\(\gamma \in (0, 1]\). The policy \(\policy ^{\ast }\) that solves this problem is commonly referred to as <span class="cmti-12">the optimal
                                                                                   
                                                                                   
policy</span>.
                                                                                   
                                                                                   
</p>
<!-- l. 26 -->
<!-- l. 26 --><p class="indent"> <a id="tailproblem_statementli1.html"></a> </p>
</body>
</html>