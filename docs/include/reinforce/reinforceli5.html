<!DOCTYPE html>

<html lang="en-US" xml:lang="en-US">
<head><title>REINFORCE algorithm</title>
<meta charset="utf-8"/>
<meta content="TeX4ht (https://tug.org/tex4ht/)" name="generator"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="reinforce.tex" name="src"/>
<script>window.MathJax = { tex: { tags: "ams", }, }; </script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<meta id="reinforce-algorithm" link="x6-5000" md-heading="REINFORCE algorithm" name="md-heading" type="h3"/></head><body>
<!-- l. 90 -->
<p><a id="x6-5001r1"></a>
</p><!-- l. 92 --><p class="indent"> </p><figure class="float" id="x6-5002r1"><span id="reinforce"></span><span></span>
<span class="cmbx-12">Algorithm 1:</span> REINFORCE
   
   <a id="x6-5003"></a>
</figure><div class="algorithmic">
<a id="x6-5004r1"></a>
<span class="ALCitem"></span><span class="ALIndent" style="width:5.87494pt;"> 
      </span><span class="cmbx-12">Input:</span>
      \(\theta _1\)
      (initial
      policy
      weights)
      <a id="x6-5005r2"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:5.87494pt;">  </span><span class="cmbx-12">for</span> learning iteration \(i := 1 \dots \mathcal I\) <span class="cmbx-12">do</span><span class="for-body">
<a id="x6-5006r3"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:17.62482pt;">    </span><span class="cmbx-12">for</span> episode \(j := 1 \dots M\) <span class="cmbx-12">do</span><span class="for-body">
<a id="x6-5007r4"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:29.3747pt;"> </span>
          obtain
          initial
          state
          \(\State _0^{j}\)
          <a id="x6-5008r5"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:29.3747pt;">       </span><span class="cmbx-12">for</span> step \(t := 0 \dots T - 1\) <span class="cmbx-12">do</span><span class="for-body">
<a id="x6-5009r6"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:41.12457pt;"> </span>
            sample
            action
            \(\Action _t^j \sim \policy ^{\theta }(\bullet \mid \State _t^{j})\)
            <a id="x6-5010r7"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:41.12457pt;"> </span>
            obtain
            state
            from
            transition
            function
            \(\State _{t+1}^j \sim \transit (\bullet \mid \State _t^j, \Action _t^j)\)
          </span><a id="x6-5011r8"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:29.3747pt;">       </span><span class="cmbx-12">end</span> <span class="cmbx-12">for</span>
</span><a id="x6-5012r9"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:17.62482pt;">    </span><span class="cmbx-12">end</span> <span class="cmbx-12">for</span><a id="x6-5013r10"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:17.62482pt;"> </span>   Perform a policy gradient step:
                                               \[ \theta _{i+1} \la \theta _i - \alpha \frac {1}{M}\sum _{j = 1}^M \sum _{t = 0}^{T-1}\sum _{t'=t}^{T-1}\left ( \gamma ^{t'} \Cost (\State _{t'}^j, \Action _{t'}^j) - B_{t}^i\right ) \nabla _{\theta }\log \pi ^{\theta }(A_t^j \mid \State _t^j)\rvert _{\theta = \theta _i}, \]
         <a id="x6-5014r11"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:17.62482pt;"> </span>   where the baseline \(B_t^i\) may be selected from any of the types specified <a href="#baseline-and-do-not-let-the-past-distract-you-principle">previously</a>,
        according to your preference.
      </span><a id="x6-5015r12"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:5.87494pt;">  </span><span class="cmbx-12">end</span> <span class="cmbx-12">for</span><a id="x6-5016r13"></a>
<a id="x6-5017r14"></a>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:5.87494pt;"> </span>
<br/><span class="ALCitem"></span><span class="ALIndent" style="width:5.87494pt;">  </span><span class="cmbx-12">return </span> Optimal policy \(\policy ^{\theta _{\mathcal I}}\)
   </div>
<!-- l. 113 -->
<!-- l. 113 --><p class="indent"> <a id="tailreinforceli5.html"></a> </p>
</body>
</html>