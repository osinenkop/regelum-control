{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Optimizable`. Documentation and examples.\n",
    "\n",
    "Here we will step-by-step motivate the use of the `Optimizable` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regelum import Optimizable\n",
    "import torch as th\n",
    "from torch.optim import Adam\n",
    "import casadi as cs\n",
    "import numpy as np\n",
    "from regelum.optimizable.core.configs import torch_default_config, casadi_default_config\n",
    "from regelum.__utilities import rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch optimization\n",
    "\n",
    "Here is how one uses PyTorch to optimize a function in the simplest way:\n",
    "\n",
    "1. Define the objective\n",
    "2. Define the optimizer and pass decision variable (parameters to optimize) to it\n",
    "3. zero_grad() -> evaluate objective -> backward() -> step() -> repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.5223e-44,  0.0000e+00], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_torch(x, y):\n",
    "    \"\"\"Whatever objective we have, we need to treat arguments as torch tensors.\"\"\"\n",
    "    return (x**2 + y**2).sum()\n",
    "\n",
    "\n",
    "x = th.Tensor([1.0, 2.0]).requires_grad_(\n",
    "    True\n",
    ")  # Here we define a tensor containing parameters to optimize\n",
    "opt_torch = Adam(params=[x], lr=0.1)\n",
    "\n",
    "# The most frequent way to optimize some objective looks like this:\n",
    "for _ in range(5000):\n",
    "    opt_torch.zero_grad()\n",
    "    obj = objective_torch(th.Tensor([1.0, 2.0]), x)\n",
    "    obj.backward()\n",
    "    opt_torch.step()\n",
    "\n",
    "x  # Intended to be about zero for both elements of tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casadi optimization\n",
    "\n",
    "Sometimes when we deal with nonlinear optimization we want to use CasADi, which is a python package\n",
    "that offers an efficient and convenient toolset for symbolic optimization.\n",
    "\n",
    "There are several APIs for nonlinear programming in CasADi. In this example we will use so-called `Opti` stack.\n",
    "\n",
    "A birdview of a common optimization routine looks like this:\n",
    "\n",
    "1. Create symbolic prototypes of variables and constant parameters\n",
    "2. Make an inference of symbolic prototype for objective and constraints\n",
    "3. Define an optimization problem and solve it with CasADi's optimization solver\n",
    "4. Retrieve the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MX(opti0_p_1), MX(opti0_x_1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_casadi(x, y):\n",
    "    return cs.sumsqr(x) + cs.sumsqr(y)\n",
    "\n",
    "\n",
    "opti = cs.Opti()  # Create an instance of Opti\n",
    "x = opti.parameter(2)  # Create a constant parameter\n",
    "y = opti.variable(2)  # Create a decistion variable\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the symbolic prototype of our objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MX((dot(opti0_p_1, opti0_p_1)+dot(opti0_x_1, opti0_x_1)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_symb = objective_casadi(x, y)\n",
    "objective_symb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our current case we obtained a human readable expression (however it's not the case in general). Next, we just pass it into `.minimize()` method and define a solver.\n",
    "\n",
    "After we call `.to_function()` method, we can invoke our optimization routine as a function that takes parameters as input arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |  25.00us ( 25.00us)   1.54us (  1.54us)         1\n",
      "  nlp_grad_f  | 105.00us ( 52.50us)   6.33us (  3.17us)         2\n",
      "       total  |  10.99ms ( 10.99ms) 685.05us (685.05us)         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DM([0, 0]), DM(5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opti.minimize(objective_symb)\n",
    "opti.solver(\n",
    "    \"ipopt\",\n",
    "    {\"print_in\": False, \"print_out\": False, \"print_time\": True},\n",
    "    {\"print_level\": 0},\n",
    ")\n",
    "opt_func = opti.to_function(\n",
    "    \"min_fun\", [x], [y, objective_symb], [\"x\"], [\"y\", \"objective_casadi\"]\n",
    ")\n",
    "opt_func(cs.DM([1.0, 2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regelum optimization\n",
    "\n",
    "As we have seen, different frameworks can be used for optimization and actually they are pretty different in usage. In `Regelum` we want to interchange between optimization frameworks depending on context and purposes: sometimes we need to learn deep neural networks, sometimes we need to make constrained optimization that is easier to solve with CasADi.\n",
    "\n",
    "This is where `Optimizable` comes in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_objective(x, y):\n",
    "    return rc.sum(x**2 + (y - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |  71.00us ( 35.50us)   4.16us (  2.08us)         2\n",
      "  nlp_grad_f  | 111.00us ( 37.00us)   6.85us (  2.28us)         3\n",
      "  nlp_hess_l  |  29.00us ( 29.00us)   1.76us (  1.76us)         1\n",
      "       total  |  13.43ms ( 13.43ms) 839.06us (839.06us)         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'y': DM([1, 1])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_regelum = Optimizable(casadi_default_config)\n",
    "x = opt_regelum.create_variable(2, 1, name=\"x\", is_constant=True)\n",
    "y = opt_regelum.create_variable(2, 1, name=\"y\")\n",
    "opt_regelum.register_objective(universal_objective, [x, y])\n",
    "opt_regelum.optimize(x=cs.DM([1.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarContainer:\n",
       "  y\n",
       "  data: tensor([1.0000, 1.0000], requires_grad=True)\n",
       "  metadata: tensor([1.0000, 1.0000], requires_grad=True)\n",
       "  dims: (2, 1)\n",
       "  is_constant: False\n",
       "\n",
       "\n",
       "  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_default_config.config_options[\"n_epochs\"] = 10000\n",
    "opt_regelum = Optimizable(torch_default_config)\n",
    "x = opt_regelum.create_variable(2, 1, name=\"x\", is_constant=True)\n",
    "y = opt_regelum.create_variable(\n",
    "    2, 1, name=\"y\", like=th.Tensor([1.0, 2.0]).requires_grad_(True)\n",
    ")\n",
    "opt_regelum.register_objective(universal_objective, [x, y])\n",
    "opt_regelum.optimize(x=th.FloatTensor([1.0, 2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regelum.model import ModelWeightContainer, ModelWeightContainerTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DM([[1, 2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWeightContainer(2, cs.DM([[1.0, 2.0], [3.0, 4.0]]))\n",
    "model(\"whatever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch = ModelWeightContainerTorch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DM(\n",
       " [[1, 2], \n",
       "  [3, 4]]),\n",
       " DM(\n",
       " [[1, 2], \n",
       "  [3, 4]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights, model.cache.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |   8.00us (  2.67us)   5.76us (  1.92us)         3\n",
      "  nlp_grad_f  |   7.00us (  1.75us)   7.70us (  1.93us)         4\n",
      "  nlp_hess_l  |   2.00us (  1.00us)   2.87us (  1.43us)         2\n",
      "       total  | 810.00us (810.00us) 809.55us (809.55us)         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w': DM(\n",
       " [[1, 1], \n",
       "  [0, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_regelum = Optimizable(casadi_default_config)\n",
    "x = opt_regelum.create_variable(1, 2, name=\"x\", is_constant=True)\n",
    "w = opt_regelum.create_variable(name=\"w\", like=model.named_parameters)\n",
    "argin_to_model = opt_regelum.create_variable(\n",
    "    1, 2, name=\"argi_to_model\", is_constant=True\n",
    ")\n",
    "y = opt_regelum.create_variable(1, 2, name=\"y\", is_nested_function=True)\n",
    "opt_regelum.connect_source(connect_to=y, func=model, source=argin_to_model, weights=w)\n",
    "opt_regelum.register_objective(universal_objective, [x, y])\n",
    "opt_regelum.optimize(x=cs.DM([1.0, 2.0]), y=cs.DM([1.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarContainer:\n",
       "  w\n",
       "  data: <bound method Module.named_parameters of ModelWeightContainerTorch()>\n",
       "  metadata: <bound method Module.named_parameters of ModelWeightContainerTorch()>\n",
       "  dims: ()\n",
       "  is_constant: False\n",
       "\n",
       "\n",
       "  y\n",
       "  data: tensor([1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
       "  metadata: tensor([1.0000, 1.0000], grad_fn=<SliceBackward0>)\n",
       "  dims: (1, 2)\n",
       "  is_constant: False\n",
       "\n",
       "\n",
       "  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_regelum = Optimizable(torch_default_config)\n",
    "x = opt_regelum.create_variable(1, 2, name=\"x\", is_constant=True)\n",
    "w = opt_regelum.create_variable(name=\"w\", like=model_torch.named_parameters)\n",
    "argin_to_model = opt_regelum.create_variable(\n",
    "    1, 2, name=\"argi_to_model\", is_constant=True, like=th.FloatTensor([1.0, 2.0])\n",
    ")\n",
    "y = opt_regelum.create_variable(1, 2, name=\"y\", is_nested_function=True)\n",
    "opt_regelum.connect_source(\n",
    "    connect_to=y, func=model_torch, source=argin_to_model, weights=w\n",
    ")\n",
    "opt_regelum.register_objective(universal_objective, [x, y])\n",
    "opt_regelum.optimize(x=th.FloatTensor([1.0, 2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inherit from `Optimizable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regelum.model import ModelPerceptron, ModelQuadLin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOptimizableObject(Optimizable):\n",
    "    def __init__(self, model, opt_config):\n",
    "        super().__init__(opt_config)\n",
    "        self.model = model\n",
    "        self.initialize_optimization_procedure()\n",
    "\n",
    "    def initialize_optimization_procedure(self):\n",
    "        self.model_weights = self.create_variable(\n",
    "            name=\"model_weights\",\n",
    "            like=self.model.named_parameters,\n",
    "        )\n",
    "        self.model_argin = self.create_variable(\n",
    "            3, 2, name=\"model_argin\", is_constant=True\n",
    "        )\n",
    "        self.model_output_reference = self.create_variable(\n",
    "            3, 1, name=\"model_output_reference\", is_constant=True\n",
    "        )\n",
    "        self.model_output = self.create_variable(\n",
    "            name=\"model_output\", is_nested_function=True\n",
    "        )\n",
    "        self.connect_source(\n",
    "            connect_to=self.model_output,\n",
    "            func=self.model,\n",
    "            source=self.model_argin,\n",
    "            weights=self.model_weights,\n",
    "        )\n",
    "        self.register_objective(\n",
    "            self.objective_function, [self.model_output, self.model_output_reference]\n",
    "        )\n",
    "        self.register_constraint(self.constr, [self.model_output])\n",
    "\n",
    "    def objective_function(self, model_output_reference, model_output):\n",
    "        return rc.sum((model_output_reference - model_output) ** 2)\n",
    "\n",
    "    def constr(self, model_output):\n",
    "        return rc.max(4 - model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_default_config.config_options[\"n_epochs\"] = 50000\n",
    "torch_default_config.config_options[\"is_reinstantiate_optimizer\"] = True\n",
    "\n",
    "model = ModelPerceptron(2, 1, 3, 3)\n",
    "optbl = MyOptimizableObject(model, torch_default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarContainer:\n",
       "  model_weights\n",
       "  data: <bound method Module.named_parameters of ModelPerceptron(\n",
       "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0-2): 3 x Linear(in_features=3, out_features=3, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
       ")>\n",
       "  metadata: <bound method Module.named_parameters of ModelPerceptron(\n",
       "  (input_layer): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0-2): 3 x Linear(in_features=3, out_features=3, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=3, out_features=1, bias=True)\n",
       ")>\n",
       "  dims: ()\n",
       "  is_constant: False\n",
       "\n",
       "\n",
       "  model_output\n",
       "  data: tensor([[6.7023],\n",
       "        [6.7004],\n",
       "        [6.7009]], grad_fn=<AddmmBackward0>)\n",
       "  metadata: tensor([[6.7023],\n",
       "        [6.7004],\n",
       "        [6.7009]], grad_fn=<AddmmBackward0>)\n",
       "  dims: ()\n",
       "  is_constant: False\n",
       "\n",
       "\n",
       "  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optbl.optimize(\n",
    "    model_output_reference=th.FloatTensor([[1.0], [3], [5]]),\n",
    "    model_argin=th.FloatTensor([[0.0, 0.0], [1, 2], [3, 5]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelQuadLin(\"symmetric\", is_with_linear_terms=False, dim_inputs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optbl = MyOptimizableObject(model, casadi_default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |  18.00us (  1.50us)  16.49us (  1.37us)        12\n",
      "       nlp_g  |  35.00us (  2.92us)  26.94us (  2.25us)        12\n",
      "  nlp_grad_f  |  18.00us (  2.57us)  16.24us (  2.32us)         7\n",
      "  nlp_hess_l  |  24.00us (  3.43us)  22.75us (  3.25us)         7\n",
      "   nlp_jac_g  |  22.00us (  2.00us)  21.62us (  1.97us)        11\n",
      "       total  |   2.55ms (  2.55ms)   2.54ms (  2.54ms)         1\n"
     ]
    }
   ],
   "source": [
    "new_weights = optbl.optimize(\n",
    "    model_output_reference=cs.DM([[1.0], [3], [5]]),\n",
    "    model_argin=cs.DM([[0.0, 0.0], [1, 2], [3, 5]]),\n",
    ")[\"model_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DM([-456.434, 492.245, -130.748])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgenv-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
